{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91172fc5-576c-4cc1-a2d6-7e68916e4c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# universal_model_benchmark.py\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, r2_score, roc_auc_score, accuracy_score, log_loss\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load datasets\n",
    "X_full_df = pd.read_csv(\"../model_food/data/financial_data_scaled.csv\")\n",
    "y_full = X_full_df[\"market_stress\"]\n",
    "X_full = X_full_df.drop(columns=[\"market_stress\"])\n",
    "\n",
    "X_pca_df = pd.read_csv(\"../model_food/data/financial_data_pca.csv\")\n",
    "y_pca = X_pca_df[\"market_stress\"]\n",
    "X_pca = X_pca_df.drop(columns=[\"market_stress\"])\n",
    "\n",
    "X_synth_df = pd.read_csv(\"../model_food/data/synth_findata.csv\")\n",
    "for col in X_synth_df.select_dtypes(include=\"object\").columns:\n",
    "    try:\n",
    "        X_synth_df[col] = pd.to_datetime(X_synth_df[col])\n",
    "        X_synth_df[col + \"_days_since_start\"] = (X_synth_df[col] - X_synth_df[col].min()).dt.days\n",
    "        X_synth_df.drop(columns=[col], inplace=True)\n",
    "    except:\n",
    "        X_synth_df.drop(columns=[col], inplace=True)\n",
    "X_synth_df = X_synth_df.select_dtypes(include=[np.number])\n",
    "y_synth = X_synth_df[\"market_stress\"]\n",
    "X_synth = X_synth_df.drop(columns=[\"market_stress\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901804a2-4ea5-4ca7-839b-3a3590780f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarking function\n",
    "def benchmark_model(name, model_path, X, y, feature_selector=None, use_predict_proba=True, thresholding=False):\n",
    "    try:\n",
    "        with open(model_path, \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "\n",
    "        if feature_selector and os.path.exists(feature_selector):\n",
    "            with open(feature_selector, \"rb\") as f:\n",
    "                selected_features = pickle.load(f)\n",
    "            X = X.iloc[:, selected_features]\n",
    "\n",
    "        start = time.time()\n",
    "        if use_predict_proba:\n",
    "            y_proba = model.predict_proba(X)[:, 1]\n",
    "        elif thresholding:\n",
    "            y_scores = model.predict(X)\n",
    "            y_proba = y_scores\n",
    "        else:\n",
    "            y_pred = model.predict(X)\n",
    "            y_proba = y_pred.astype(float)\n",
    "\n",
    "        y_pred = (y_proba >= 0.5).astype(int)\n",
    "        elapsed = time.time() - start\n",
    "\n",
    "        metrics = {\n",
    "            \"Model\": name,\n",
    "            \"MSE\": mean_squared_error(y, y_proba),\n",
    "            \"R² Score\": r2_score(y, y_proba),\n",
    "            \"ROC-AUC Score\": roc_auc_score(y, y_proba),\n",
    "            \"Accuracy Score\": accuracy_score(y, y_pred),\n",
    "            \"Log Loss\": log_loss(y, y_proba),\n",
    "            \"Prediction Time (s)\": elapsed,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            stability = np.mean(cross_val_score(model, X, y, cv=5))\n",
    "        except:\n",
    "            stability = np.nan\n",
    "\n",
    "        metrics[\"Hotness\"] = stability\n",
    "        metrics[\"Cleverness\"] = (metrics[\"ROC-AUC Score\"] + metrics[\"Accuracy Score\"]) / 2\n",
    "        metrics[\"Fitness Score\"] = (\n",
    "            metrics[\"ROC-AUC Score\"] + metrics[\"Accuracy Score\"] + (stability if not np.isnan(stability) else 0)\n",
    "        ) / (3 if not np.isnan(stability) else 2)\n",
    "        metrics[\"Lineage\"] = \"Universal Benchmark\"\n",
    "        return metrics\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"Model\": name, \"Error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1aed4fb-2567-4a47-ae47-2a36278c72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models to benchmark\n",
    "model_configs = [\n",
    "    (\"CNN (MLP)\", \"OGOGszz/saved_models/CNN (MLP).pkl\", X_full, y_full, \"saved_models/CNN_selected_features.pkl\"),\n",
    "    (\"Diffusion (GMM)\", \"OGOGszz/saved_models/Diffusion_Model_GMM.pkl\", X_pca, y_pca, None),\n",
    "    (\"Elastic Net\", \"OGOGszz/saved_models/Elastic Net.pkl\", X_full, y_full, None, False, True),\n",
    "    (\"GA-Optimized LR\", \"OGOGszz/saved_models/GA-Optimized LR.pkl\", X_full, y_full, \"saved_models/GA_selected_features.pkl\"),\n",
    "    (\"Gradient Boosting\", \"OGOGszz/saved_models/GradientBoosting.pkl\", X_full, y_full),\n",
    "    (\"NeuroEvolution (NEAT)\", \"OGOGszz/saved_models/NeuroEvolution (NEAT).pkl\", X_full, y_full),\n",
    "    (\"SGD\", \"OGOGszz/saved_models/SGD.pkl\", X_full, y_full)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3570f624-67c5-4f9b-ba7a-1f3be4754698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophiaboettcher/anaconda3/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/sophiaboettcher/anaconda3/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but GaussianMixture was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/sophiaboettcher/anaconda3/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/sophiaboettcher/anaconda3/lib/python3.11/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but SGDClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run benchmarks\n",
    "results = []\n",
    "for config in model_configs:\n",
    "    result = benchmark_model(*config)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26f8eecc-db72-4572-b56a-c75fbc268010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Benchmarking complete. Results saved to model_performance_universal.csv\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"OGOGszz/perf/model_performance_universal.csv\", index=False)\n",
    "print(\"✅ Benchmarking complete. Results saved to model_performance_universal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4747b3e-c7ea-429a-afe4-5eb11eadf41e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
