{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14cb515-7617-4cc0-93cc-c96b17c09dc8",
   "metadata": {},
   "source": [
    "üìì CNN PCA Graph Forecasting Notebook\n",
    "\n",
    "Train a CNN to learn latent PCA macroeconomic trendlines from 15-year historical graphs to 2-year projected trajectories.\n",
    "\n",
    "---\n",
    "\n",
    "üß© Cell 1 ‚Äì Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d749ac5f-6943-4336-98dc-f34f388a49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8530313-1d41-43f7-bcd4-2dbec461f96f",
   "metadata": {},
   "source": [
    "‚öôÔ∏è Cell 2 ‚Äì Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e36460-0e9e-4f36-beb1-269a69a9173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config ---\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 256\n",
    "BATCH_SIZE = 16\n",
    "DATA_ROOT = \"pca_graph_pairs\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6220d25e-4d7f-4eaa-bc53-5aa56ed3ef5a",
   "metadata": {},
   "source": [
    "üìÅ Cell 3 ‚Äì Custom Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ab961e-bd1f-4b71-aa62-c26ac0f091b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset ---\n",
    "class GraphImageDataset(Dataset):\n",
    "    def __init__(self, meta_csv, transform=None):\n",
    "        self.df = pd.read_csv(meta_csv)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        input_img = Image.open(row[\"input_img\"]).convert(\"RGB\").resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "        output_img = Image.open(row[\"output_img\"]).convert(\"RGB\").resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "        if self.transform:\n",
    "            input_img = self.transform(input_img)\n",
    "            output_img = self.transform(output_img)\n",
    "        return input_img, output_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54932647-a338-4606-bfc4-2146d595da01",
   "metadata": {},
   "source": [
    "üé® Cell 4 ‚Äì Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6633e59-323a-44e0-bc7a-d81fe7840f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Transforms ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c22b9c5-be9a-439b-b7de-1fe81520380e",
   "metadata": {},
   "source": [
    "üß† Cell 6 ‚Äì CNN Architecture (U-Net-style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a58224d1-48ba-4190-ac45-ee357f327523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model ---\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, 2, 1),  # -> (32, 64, 128)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1), # -> (64, 32, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),# -> (128, 16, 32)\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # -> (64, 32, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),   # -> (32, 64, 128)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 4, 2, 1),    # -> (3, 128, 256)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45378960-d363-44c7-91db-47e3eddf99e0",
   "metadata": {},
   "source": [
    "üß∞ Cell 7 ‚Äì Initialize Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af43561d-1691-4561-9b32-e66a9020d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe2e72df-2236-43ab-817a-eaffc16c71b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 15485 samples for training.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Data ---\n",
    "# dataset = GraphImageDataset(meta_csv=os.path.join(DATA_ROOT, \"pairs_metadata.csv\"), transform=transform)\n",
    "# dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Load PCA graph image dataset\n",
    "dataset = GraphImageDataset(\n",
    "    meta_csv=os.path.join(\"pca_graph_pairs\", \"pairs_metadata.csv\"),\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "# Initialize DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(dataset)} samples for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a4aab-50e7-4a34-8ed0-bdaa06b9888f",
   "metadata": {},
   "source": [
    "üèãÔ∏è‚Äç‚ôÇÔ∏è Cell 8 ‚Äì Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20cec633-7741-422c-993b-a287d814a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.0250\n",
      "Epoch 2/10 - Loss: 0.0173\n",
      "Epoch 3/10 - Loss: 0.0173\n",
      "Epoch 4/10 - Loss: 0.0173\n",
      "Epoch 5/10 - Loss: 0.0173\n",
      "Epoch 6/10 - Loss: 0.0172\n",
      "Epoch 7/10 - Loss: 0.0166\n",
      "Epoch 8/10 - Loss: 0.0101\n",
      "Epoch 9/10 - Loss: 0.0093\n",
      "Epoch 10/10 - Loss: 0.0090\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        x, y = batch\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2b125-e598-424f-927b-cdf701be4595",
   "metadata": {},
   "source": [
    "üíæ Cell 9 ‚Äì Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3edd1d8f-ee0a-402a-83da-d951ad6b49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save model ---\n",
    "torch.save(model.state_dict(), \"cnn_pca_forecaster.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50376986-8058-44ca-a901-1bd24e9ce288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
